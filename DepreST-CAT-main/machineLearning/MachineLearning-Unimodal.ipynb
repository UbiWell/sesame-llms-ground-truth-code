{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "#Author: ML Tlachac, WPI\n",
    "#For DepreST-CAT, 2021\n",
    "\n",
    "import pandas as pd\n",
    "import numpy as np\n",
    "import matplotlib.pyplot as plt\n",
    "from sklearn.feature_selection import SelectKBest, chi2\n",
    "from sklearn import preprocessing\n",
    "from scipy import stats\n",
    "import collections\n",
    "import operator\n",
    "import argparse\n",
    "import random\n",
    "from sklearn.model_selection import cross_validate\n",
    "from sklearn.model_selection import cross_val_predict\n",
    "from sklearn.model_selection import train_test_split\n",
    "from sklearn.metrics import confusion_matrix\n",
    "from sklearn.metrics import recall_score\n",
    "from sklearn import metrics\n",
    "from statistics import mean \n",
    "from sklearn.naive_bayes import GaussianNB\n",
    "from sklearn.utils import resample\n",
    "from sklearn import preprocessing\n",
    "from sklearn import utils\n",
    "from sklearn.datasets import load_digits\n",
    "from sklearn import svm\n",
    "import xgboost as xgb\n",
    "from sklearn.neighbors import KNeighborsClassifier\n",
    "from sklearn.linear_model import LogisticRegression\n",
    "from sklearn.ensemble import RandomForestClassifier\n",
    "import random\n",
    "from sklearn.decomposition import PCA, KernelPCA, NMF"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {
    "tags": []
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "(369, 571)\n",
      "['id', 'inCalls0_Absolute energy', 'inCalls0_Area under the curve', 'inCalls0_Autocorrelation', 'inCalls0_Centroid', 'inCalls0_ECDF Percentile Count_0', 'inCalls0_ECDF Percentile Count_1', 'inCalls0_ECDF Percentile_0', 'inCalls0_ECDF Percentile_1', 'inCalls0_ECDF_0', 'inCalls0_ECDF_1', 'inCalls0_ECDF_2', 'inCalls0_ECDF_3', 'inCalls0_ECDF_4', 'inCalls0_ECDF_5', 'inCalls0_ECDF_6', 'inCalls0_ECDF_7', 'inCalls0_ECDF_8', 'inCalls0_ECDF_9', 'inCalls0_Entropy', 'inCalls0_FFT mean coefficient_0', 'inCalls0_FFT mean coefficient_1', 'inCalls0_FFT mean coefficient_2', 'inCalls0_FFT mean coefficient_3', 'inCalls0_FFT mean coefficient_4', 'inCalls0_FFT mean coefficient_5', 'inCalls0_FFT mean coefficient_6', 'inCalls0_FFT mean coefficient_7', 'inCalls0_Fundamental frequency', 'inCalls0_Histogram_0', 'inCalls0_Histogram_1', 'inCalls0_Histogram_2', 'inCalls0_Histogram_3', 'inCalls0_Histogram_4', 'inCalls0_Histogram_5', 'inCalls0_Histogram_6', 'inCalls0_Histogram_7', 'inCalls0_Histogram_8', 'inCalls0_Histogram_9', 'inCalls0_Human range energy', 'inCalls0_Interquartile range', 'inCalls0_Kurtosis', 'inCalls0_LPCC_0', 'inCalls0_LPCC_1', 'inCalls0_LPCC_10', 'inCalls0_LPCC_11', 'inCalls0_LPCC_12', 'inCalls0_LPCC_2', 'inCalls0_LPCC_3', 'inCalls0_LPCC_4', 'inCalls0_LPCC_5', 'inCalls0_LPCC_6', 'inCalls0_LPCC_7', 'inCalls0_LPCC_8', 'inCalls0_LPCC_9', 'inCalls0_MFCC_0', 'inCalls0_MFCC_1', 'inCalls0_MFCC_10', 'inCalls0_MFCC_11', 'inCalls0_MFCC_2', 'inCalls0_MFCC_3', 'inCalls0_MFCC_4', 'inCalls0_MFCC_5', 'inCalls0_MFCC_6', 'inCalls0_MFCC_7', 'inCalls0_MFCC_8', 'inCalls0_MFCC_9', 'inCalls0_Max', 'inCalls0_Max power spectrum', 'inCalls0_Maximum frequency', 'inCalls0_Mean', 'inCalls0_Mean absolute deviation', 'inCalls0_Mean absolute diff', 'inCalls0_Mean diff', 'inCalls0_Median', 'inCalls0_Median absolute deviation', 'inCalls0_Median absolute diff', 'inCalls0_Median diff', 'inCalls0_Median frequency', 'inCalls0_Min', 'inCalls0_Negative turning points', 'inCalls0_Neighbourhood peaks', 'inCalls0_Peak to peak distance', 'inCalls0_Positive turning points', 'inCalls0_Power bandwidth', 'inCalls0_Root mean square', 'inCalls0_Signal distance', 'inCalls0_Skewness', 'inCalls0_Slope', 'inCalls0_Spectral centroid', 'inCalls0_Spectral decrease', 'inCalls0_Spectral distance', 'inCalls0_Spectral entropy', 'inCalls0_Spectral kurtosis', 'inCalls0_Spectral positive turning points', 'inCalls0_Spectral roll-off', 'inCalls0_Spectral roll-on', 'inCalls0_Spectral skewness', 'inCalls0_Spectral slope', 'inCalls0_Spectral spread', 'inCalls0_Spectral variation', 'inCalls0_Standard deviation', 'inCalls0_Sum absolute diff', 'inCalls0_Total energy', 'inCalls0_Variance', 'inCalls0_Wavelet absolute mean_0', 'inCalls0_Wavelet absolute mean_1', 'inCalls0_Wavelet absolute mean_2', 'inCalls0_Wavelet absolute mean_3', 'inCalls0_Wavelet absolute mean_4', 'inCalls0_Wavelet absolute mean_5', 'inCalls0_Wavelet absolute mean_6', 'inCalls0_Wavelet absolute mean_7', 'inCalls0_Wavelet absolute mean_8', 'inCalls0_Wavelet energy_0', 'inCalls0_Wavelet energy_1', 'inCalls0_Wavelet energy_2', 'inCalls0_Wavelet energy_3', 'inCalls0_Wavelet energy_4', 'inCalls0_Wavelet energy_5', 'inCalls0_Wavelet energy_6', 'inCalls0_Wavelet energy_7', 'inCalls0_Wavelet energy_8', 'inCalls0_Wavelet entropy', 'inCalls0_Wavelet standard deviation_0', 'inCalls0_Wavelet standard deviation_1', 'inCalls0_Wavelet standard deviation_2', 'inCalls0_Wavelet standard deviation_3', 'inCalls0_Wavelet standard deviation_4', 'inCalls0_Wavelet standard deviation_5', 'inCalls0_Wavelet standard deviation_6', 'inCalls0_Wavelet standard deviation_7', 'inCalls0_Wavelet standard deviation_8', 'inCalls0_Wavelet variance_0', 'inCalls0_Wavelet variance_1', 'inCalls0_Wavelet variance_2', 'inCalls0_Wavelet variance_3', 'inCalls0_Wavelet variance_4', 'inCalls0_Wavelet variance_5', 'inCalls0_Wavelet variance_6', 'inCalls0_Wavelet variance_7', 'inCalls0_Wavelet variance_8', 'inCalls0_Zero crossing rate', 'outCalls0_Absolute energy', 'outCalls0_Area under the curve', 'outCalls0_Autocorrelation', 'outCalls0_Centroid', 'outCalls0_ECDF Percentile Count_0', 'outCalls0_ECDF Percentile Count_1', 'outCalls0_ECDF Percentile_0', 'outCalls0_ECDF Percentile_1', 'outCalls0_ECDF_0', 'outCalls0_ECDF_1', 'outCalls0_ECDF_2', 'outCalls0_ECDF_3', 'outCalls0_ECDF_4', 'outCalls0_ECDF_5', 'outCalls0_ECDF_6', 'outCalls0_ECDF_7', 'outCalls0_ECDF_8', 'outCalls0_ECDF_9', 'outCalls0_Entropy', 'outCalls0_FFT mean coefficient_0', 'outCalls0_FFT mean coefficient_1', 'outCalls0_FFT mean coefficient_2', 'outCalls0_FFT mean coefficient_3', 'outCalls0_FFT mean coefficient_4', 'outCalls0_FFT mean coefficient_5', 'outCalls0_FFT mean coefficient_6', 'outCalls0_FFT mean coefficient_7', 'outCalls0_Fundamental frequency', 'outCalls0_Histogram_0', 'outCalls0_Histogram_1', 'outCalls0_Histogram_2', 'outCalls0_Histogram_3', 'outCalls0_Histogram_4', 'outCalls0_Histogram_5', 'outCalls0_Histogram_6', 'outCalls0_Histogram_7', 'outCalls0_Histogram_8', 'outCalls0_Histogram_9', 'outCalls0_Human range energy', 'outCalls0_Interquartile range', 'outCalls0_Kurtosis', 'outCalls0_LPCC_0', 'outCalls0_LPCC_1', 'outCalls0_LPCC_10', 'outCalls0_LPCC_11', 'outCalls0_LPCC_12', 'outCalls0_LPCC_2', 'outCalls0_LPCC_3', 'outCalls0_LPCC_4', 'outCalls0_LPCC_5', 'outCalls0_LPCC_6', 'outCalls0_LPCC_7', 'outCalls0_LPCC_8', 'outCalls0_LPCC_9', 'outCalls0_MFCC_0', 'outCalls0_MFCC_1', 'outCalls0_MFCC_10', 'outCalls0_MFCC_11', 'outCalls0_MFCC_2', 'outCalls0_MFCC_3', 'outCalls0_MFCC_4', 'outCalls0_MFCC_5', 'outCalls0_MFCC_6', 'outCalls0_MFCC_7', 'outCalls0_MFCC_8', 'outCalls0_MFCC_9', 'outCalls0_Max', 'outCalls0_Max power spectrum', 'outCalls0_Maximum frequency', 'outCalls0_Mean', 'outCalls0_Mean absolute deviation', 'outCalls0_Mean absolute diff', 'outCalls0_Mean diff', 'outCalls0_Median', 'outCalls0_Median absolute deviation', 'outCalls0_Median absolute diff', 'outCalls0_Median diff', 'outCalls0_Median frequency', 'outCalls0_Min', 'outCalls0_Negative turning points', 'outCalls0_Neighbourhood peaks', 'outCalls0_Peak to peak distance', 'outCalls0_Positive turning points', 'outCalls0_Power bandwidth', 'outCalls0_Root mean square', 'outCalls0_Signal distance', 'outCalls0_Skewness', 'outCalls0_Slope', 'outCalls0_Spectral centroid', 'outCalls0_Spectral decrease', 'outCalls0_Spectral distance', 'outCalls0_Spectral entropy', 'outCalls0_Spectral kurtosis', 'outCalls0_Spectral positive turning points', 'outCalls0_Spectral roll-off', 'outCalls0_Spectral roll-on', 'outCalls0_Spectral skewness', 'outCalls0_Spectral slope', 'outCalls0_Spectral spread', 'outCalls0_Spectral variation', 'outCalls0_Standard deviation', 'outCalls0_Sum absolute diff', 'outCalls0_Total energy', 'outCalls0_Variance', 'outCalls0_Wavelet absolute mean_0', 'outCalls0_Wavelet absolute mean_1', 'outCalls0_Wavelet absolute mean_2', 'outCalls0_Wavelet absolute mean_3', 'outCalls0_Wavelet absolute mean_4', 'outCalls0_Wavelet absolute mean_5', 'outCalls0_Wavelet absolute mean_6', 'outCalls0_Wavelet absolute mean_7', 'outCalls0_Wavelet absolute mean_8', 'outCalls0_Wavelet energy_0', 'outCalls0_Wavelet energy_1', 'outCalls0_Wavelet energy_2', 'outCalls0_Wavelet energy_3', 'outCalls0_Wavelet energy_4', 'outCalls0_Wavelet energy_5', 'outCalls0_Wavelet energy_6', 'outCalls0_Wavelet energy_7', 'outCalls0_Wavelet energy_8', 'outCalls0_Wavelet entropy', 'outCalls0_Wavelet standard deviation_0', 'outCalls0_Wavelet standard deviation_1', 'outCalls0_Wavelet standard deviation_2', 'outCalls0_Wavelet standard deviation_3', 'outCalls0_Wavelet standard deviation_4', 'outCalls0_Wavelet standard deviation_5', 'outCalls0_Wavelet standard deviation_6', 'outCalls0_Wavelet standard deviation_7', 'outCalls0_Wavelet standard deviation_8', 'outCalls0_Wavelet variance_0', 'outCalls0_Wavelet variance_1', 'outCalls0_Wavelet variance_2', 'outCalls0_Wavelet variance_3', 'outCalls0_Wavelet variance_4', 'outCalls0_Wavelet variance_5', 'outCalls0_Wavelet variance_6', 'outCalls0_Wavelet variance_7', 'outCalls0_Wavelet variance_8', 'outCalls0_Zero crossing rate', 'phq9', 'gad7']\n"
     ]
    },
    {
     "ename": "NameError",
     "evalue": "name 'abc' is not defined",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mNameError\u001b[0m                                 Traceback (most recent call last)",
      "Input \u001b[0;32mIn [7]\u001b[0m, in \u001b[0;36m<cell line: 5>\u001b[0;34m()\u001b[0m\n\u001b[1;32m     18\u001b[0m tnames \u001b[38;5;241m=\u001b[39m [\u001b[38;5;124m'\u001b[39m\u001b[38;5;124mid\u001b[39m\u001b[38;5;124m'\u001b[39m] \u001b[38;5;241m+\u001b[39m \u001b[38;5;28mlist\u001b[39m(data\u001b[38;5;241m.\u001b[39mcolumns[tids]) \u001b[38;5;241m+\u001b[39m [\u001b[38;5;124m'\u001b[39m\u001b[38;5;124mphq9\u001b[39m\u001b[38;5;124m'\u001b[39m,\u001b[38;5;124m'\u001b[39m\u001b[38;5;124mgad7\u001b[39m\u001b[38;5;124m'\u001b[39m]\n\u001b[1;32m     20\u001b[0m \u001b[38;5;28mprint\u001b[39m(cnames)\n\u001b[0;32m---> 21\u001b[0m \u001b[38;5;28mprint\u001b[39m(\u001b[43mabc\u001b[49m)\n\u001b[1;32m     23\u001b[0m calls \u001b[38;5;241m=\u001b[39m data[cnames]\n\u001b[1;32m     24\u001b[0m texts \u001b[38;5;241m=\u001b[39m data[tnames]\n",
      "\u001b[0;31mNameError\u001b[0m: name 'abc' is not defined"
     ]
    }
   ],
   "source": [
    "labels = [\"phq9\", \"gad7\"]\n",
    "modelTypelist = [\"SVC\", \"kNN\", \"RF\", \"LR\", \"XG\"]\n",
    "splits = [5,6,7,8,9,10]\n",
    "\n",
    "for split in splits: \n",
    "    \n",
    "    for week in [2,4,8,16]:\n",
    "\n",
    "        data = pd.read_csv(\"../features/featureSet\" + str(week) + \"weeksDepreST-CAT.csv\")\n",
    "        print(data.shape)\n",
    "        \n",
    "        n = int((data.shape[1]-3)/2)\n",
    "        \n",
    "        cids = range(n+1, data.shape[1]-2)\n",
    "        tids = range(1, n+1)\n",
    "        \n",
    "        cnames = ['id'] + list(data.columns[cids]) + ['phq9','gad7']\n",
    "        tnames = ['id'] + list(data.columns[tids]) + ['phq9','gad7']\n",
    "        \n",
    "        print(cnames)\n",
    "        print(abc)\n",
    "                \n",
    "        calls = data[cnames]\n",
    "        texts = data[tnames]\n",
    "        \n",
    "        data = texts\n",
    "        print(data.shape)\n",
    "\n",
    "        #binary labels\n",
    "        d10 = []\n",
    "        g10 = []\n",
    "        for i in range(0, data.shape[0]):\n",
    "            if int(data.phq9[i]) >= split:\n",
    "                d10.append(1)\n",
    "            else:\n",
    "                d10.append(0)\n",
    "            if int(data.gad7[i]) >= split:\n",
    "                g10.append(1)\n",
    "            else:\n",
    "                g10.append(0)\n",
    "        data[\"phq9\"] = d10\n",
    "        data[\"gad7\"] = g10\n",
    "        \n",
    "        for label in labels:\n",
    "\n",
    "            #create lists to populate\n",
    "            flist = [] \n",
    "            mlist = []\n",
    "            llist = []\n",
    "            featureList = []\n",
    "            wlist = []\n",
    "            slist = []\n",
    "            f1List = []\n",
    "            accuracyList = []\n",
    "            truePosList = []\n",
    "            trueNegList = []\n",
    "            falsePosList = []\n",
    "            falseNegList = []\n",
    "            predictions = []\n",
    "            rseed = []\n",
    "\n",
    "            for r in range(0, 100):\n",
    "\n",
    "                #train/test split    \n",
    "                df_train, df_test = train_test_split(data, test_size=0.3, stratify=data[[\"phq9\", \"gad7\"]], random_state = r)\n",
    "                trainids = list(df_train[\"id\"])\n",
    "                testids = list(df_test[\"id\"])\n",
    "                print(data.shape)\n",
    "                testdata = data[data['id'].isin(testids)]\n",
    "                print(testdata.shape)\n",
    "                traindata = data[data['id'].isin(trainids)]\n",
    "                print(traindata.shape)\n",
    "\n",
    "                #limit to features\n",
    "                testContent = testdata[testdata.columns[1:-2]]\n",
    "                print(testContent.shape)\n",
    "                trainContent = traindata[traindata.columns[1:-2]]\n",
    "                print(trainContent.shape)\n",
    "\n",
    "                #NEED TO SCALE BEFORE FEATURE SELECTION/REDUCATION\n",
    "                min_max_scaler = preprocessing.MinMaxScaler()  \n",
    "                np_scaled = min_max_scaler.fit_transform(trainContent)\n",
    "                featureSubset = pd.DataFrame(np_scaled)\n",
    "                np_scaled2 =  min_max_scaler.transform(testContent)\n",
    "                testSubset = pd.DataFrame(np_scaled2)\n",
    "                print(featureSubset.shape)\n",
    "                print(testSubset.shape)\n",
    "\n",
    "                target = list(traindata[label])\n",
    "\n",
    "                featureDF = []\n",
    "                testDFs = []\n",
    "\n",
    "                nFeatureList = list(np.arange(1,5,1))\n",
    "                for numberOfFeatures in nFeatureList:\n",
    "                    pca = PCA(n_components=numberOfFeatures)\n",
    "                    pca = pca.fit(featureSubset)\n",
    "                    X_pca = pca.transform(featureSubset)\n",
    "                    pcaDF = pd.DataFrame(X_pca)\n",
    "                    pcaDF = pcaDF.assign(target = target)\n",
    "                    featureDF.append(pcaDF)\n",
    "                    testSubset2 = pca.transform(testSubset)\n",
    "                    testDFs.append(pd.DataFrame(testSubset2))\n",
    "\n",
    "\n",
    "                for f in range(0, len(featureDF)):\n",
    "                    print(f)\n",
    "\n",
    "                    train_phq9 = featureDF[f]\n",
    "                    X_test = testDFs[f]\n",
    "\n",
    "                    # upsampling \n",
    "                    #Count 1s and 0s\n",
    "                    ones = len(train_phq9.loc[train_phq9['target'] == 1])\n",
    "                    zeros = len(train_phq9.loc[train_phq9['target'] == 0])\n",
    "                    if ones >= zeros:\n",
    "                        majority = 1\n",
    "                        minority = 0\n",
    "                    else:\n",
    "                        majority = 0\n",
    "                        minority = 1\n",
    "\n",
    "\n",
    "                    # Upsample TrainingSet \n",
    "                    train_majority = train_phq9[train_phq9.target==majority]\n",
    "                    train_minority = train_phq9[train_phq9.target==minority]\n",
    "\n",
    "                    #print(\"train_majority =\"  + str(len(train_majority)))\n",
    "                    #print(\"train_minority =\"  + str(len(train_minority)))\n",
    "\n",
    "                    # Upsample minority class\n",
    "                    train_minority_upsampled = resample(train_minority, \n",
    "                                                     replace=True,     # sample with replacement\n",
    "                                                     n_samples=len(train_majority),    # to match majority class\n",
    "                                                     random_state=42) # reproducible results\n",
    "\n",
    "                    # Combine majority class with upsampled minority class\n",
    "                    train_phq9 = pd.concat([train_majority, train_minority_upsampled])\n",
    "\n",
    "                    #seperate features and target\n",
    "                    y_train = train_phq9[\"target\"]\n",
    "                    X_train = train_phq9.drop(columns = \"target\")\n",
    "\n",
    "                    for modelType in modelTypelist:\n",
    "\n",
    "                        #add data to lists\n",
    "                        llist.append(label)\n",
    "                        featureList.append(f +1)\n",
    "                        flist.append(\"PCA\")\n",
    "                        mlist.append(modelType)\n",
    "\n",
    "                        #chose model type\n",
    "                        if modelType == \"SVC\":\n",
    "                            clf = svm.SVC(random_state=r)\n",
    "                        elif modelType == \"RF\":\n",
    "                            clf = RandomForestClassifier(random_state=r)\n",
    "                        elif modelType == \"kNN\":\n",
    "                            clf = KNeighborsClassifier()\n",
    "                        elif modelType == \"LR\":\n",
    "                            clf = LogisticRegression(random_state=r)\n",
    "                        elif modelType ==\"XG\":\n",
    "                            clf = xgb.XGBClassifier(random_state=r)\n",
    "\n",
    "                        #train model and make predictions\n",
    "                        clf.fit(X_train, y_train)\n",
    "                        y_pred = clf.predict(X_test)\n",
    "\n",
    "                        #evaluate model\n",
    "                        conf_mat = confusion_matrix(list(testdata[label]), y_pred)\n",
    "                        TN = conf_mat[0][0]\n",
    "                        TP = conf_mat[1][1]\n",
    "                        FP = conf_mat[0][1]\n",
    "                        FN = conf_mat[1][0]\n",
    "                        precision = TP/(TP+FP)\n",
    "                        sensitivity = TP/(TP+FN)\n",
    "                        f1 = (2*precision*sensitivity)/(precision + sensitivity)\n",
    "                        accuracy = (TP+TN)/(TN+TP+FP+FN)\n",
    "\n",
    "                        #populate lists with results\n",
    "                        f1List.append(f1)\n",
    "                        accuracyList.append(accuracy)\n",
    "                        truePosList.append(TP)\n",
    "                        trueNegList.append(TN)\n",
    "                        falsePosList.append(FP)\n",
    "                        falseNegList.append(FN)\n",
    "                        predictions.append(y_pred)\n",
    "                        rseed.append(r)\n",
    "                        slist.append(split)\n",
    "                        wlist.append(week)\n",
    "\n",
    "            resultsDF = pd.DataFrame()\n",
    "            resultsDF[\"week\"] = wlist\n",
    "            resultsDF[\"label\"] = llist\n",
    "            resultsDF[\"split\"] = slist\n",
    "            resultsDF[\"Engineering\"] = flist\n",
    "            resultsDF[\"model\"] = mlist\n",
    "            resultsDF[\"nFeatures\"] = featureList\n",
    "            resultsDF[\"F1\"] = f1List\n",
    "            resultsDF[\"Accuracy\"] = accuracyList\n",
    "            resultsDF[\"truePos\"] = truePosList\n",
    "            resultsDF[\"trueNeg\"] = trueNegList\n",
    "            resultsDF[\"falsePos\"] = falsePosList\n",
    "            resultsDF[\"falseNeg\"] = falseNegList\n",
    "            resultsDF[\"predictions\"] = predictions\n",
    "            resultsDF[\"randomSeed\"] = rseed\n",
    "\n",
    "            resultsDF.to_csv(\"resultsText/resultsCAT\" + str(week) + \"week\" + label + \"split\" + str(split) + \".csv\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 88,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "______________phq9_______________\n",
      "WEEK:2\n",
      "kNN F1: $0.68\\pm0.04$\n",
      "______________gad7_______________\n",
      "WEEK:2\n",
      "kNN F1: $0.63\\pm0.05$\n"
     ]
    }
   ],
   "source": [
    "score = \"F1\"\n",
    "for label in [\"phq9\", \"gad7\"]:\n",
    "    print(\"______________\" + label + \"_______________\")\n",
    "    for week in ['2']:\n",
    "        print(\"WEEK:\" + week)\n",
    "        df = pd.read_csv(\"results/resultsCAT\" + str(week) + \"week\" + label + \"split5.csv\")\n",
    "        for model in [\"kNN\"]:\n",
    "            d = df[df.model == model]\n",
    "            d1 = d[d.nFeatures == 1].fillna(0)\n",
    "            print(model + \" \" +  str(score) + \": $\" + str(round(sum(d1[score])/100,2)) + \"\\pm\" + str(round(np.std(d1[score]),2)) + \"$\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "basicpy",
   "language": "python",
   "name": "basicpy"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.9.12"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
